# Performance Predictor Service Configuration
# Copy this file to .env and fill in your values

# ======================
# Service Configuration
# ======================
SERVICE_NAME=performance-predictor
VERSION=1.0.0
DEBUG=false
LOG_LEVEL=INFO

# ======================
# Server Configuration
# ======================
HOST=0.0.0.0
PORT=8001

# ======================
# Database Configuration
# ======================
# PostgreSQL database for learning system and historical data
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/performance_predictor
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10

# ======================
# Redis Configuration
# ======================
# Redis for caching predictions and feature data
REDIS_URL=redis://localhost:6379/0
REDIS_TTL_SECONDS=3600
PREDICTION_CACHE_TTL=1800

# ======================
# ML Model Configuration
# ======================
# Directory where trained models are stored
MODELS_DIR=./models

# Model type: xgboost, gradient_boosting, random_forest, hist_gradient_boosting
MODEL_TYPE=xgboost

# Inference cache size (number of predictions to cache)
INFERENCE_CACHE_SIZE=1000

# Enable model preloading at startup
PRELOAD_MODELS=true

# ======================
# OpenAI Configuration
# ======================
# Used for content analysis and recommendations
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# ======================
# Learning System
# ======================
# Enable the learning system for model improvement
LEARNING_ENABLED=true

# Minimum samples before retraining
MIN_SAMPLES_FOR_RETRAIN=100

# Retrain frequency (hours)
RETRAIN_FREQUENCY_HOURS=24

# ======================
# Feature Configuration
# ======================
# Trending data refresh interval (minutes)
TRENDING_REFRESH_INTERVAL=30

# Maximum hashtags to analyze
MAX_HASHTAGS_ANALYZED=30

# ======================
# Platform API Keys (Optional)
# ======================
# For real-time trending data and analytics
TIKTOK_API_KEY=
INSTAGRAM_API_KEY=
YOUTUBE_API_KEY=

# ======================
# A/B Testing Configuration
# ======================
# Enable A/B testing between model versions
AB_TESTING_ENABLED=true

# Default traffic split for new model versions (0.0 to 1.0)
AB_TEST_DEFAULT_TRAFFIC=0.1

# ======================
# Performance Tuning
# ======================
# Maximum batch size for predictions
MAX_BATCH_SIZE=50

# Request timeout (seconds)
REQUEST_TIMEOUT=30

# Worker concurrency for batch processing
BATCH_CONCURRENCY=5

# ======================
# Monitoring (Optional)
# ======================
# Prometheus metrics endpoint
METRICS_ENABLED=true
METRICS_PORT=9090

# Sentry error tracking
SENTRY_DSN=
